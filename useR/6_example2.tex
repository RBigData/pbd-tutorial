% % % % \section[Iris]{In-Depth Example Examining the Iris Dataset with pbdR}
% % % % 
% % % % \hidenum
% % % % \begin{frame}[noframenumbering]
% % % % \frametitle{Contents}
% % % %  \tableofcontents[currentsection,hideothersubsections,sectionstyle=show/hide]
% % % % \end{frame}
% % % % \shownum
% % % % 
% % % % \subsection{Examining the Iris Dataset}
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{The Iris Dataset}\pause
% % % % \begin{lstlisting}
% % % % rm(list = ls())                   # Clean environment
% % % % 
% % % % library(pbdMPI, quiet = TRUE)     # Load library
% % % % if(comm.size() != 4)
% % % %   comm.stop("4 processors are required.")
% % % % 
% % % % ### Load data
% % % % X <- as.matrix(iris[, -5])        # Dimension 150 by 4
% % % % X.cid <- as.numeric(iris[, 5])    # True id
% % % % 
% % % % ### Distribute data
% % % % jid <- get.jid(nrow(X))
% % % % X.spmd <- X[jid,]                 # SPMD row-major format
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{Standardizing}\pause
% % % % \begin{lstlisting}
% % % % ### Standardized
% % % % N <- allreduce(nrow(X.spmd))             # 150
% % % % p <- ncol(X.spmd)                        # 4
% % % % mu <- allreduce(colSums(X.spmd / N))
% % % % X.std <- sweep(X.spmd, 2, mu, FUN = "-") # Substract mean
% % % % std <- sqrt(allreduce(colSums(X.std^2 / (N - 1))))
% % % % X.std <- sweep(X.std, 2, std, FUN = "/") # Divide standard error
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{Projection Onto First 2 PC's}\pause
% % % % \begin{lstlisting}
% % % % ### SVD manually in serial
% % % % X.tmp <- crossprod(X.std)        # X'X (local)
% % % % X.tmp <- allreduce(X.tmp)
% % % % dim(X.tmp) <- c(p, p)
% % % % ret <- eigen(X.tmp)              # X'X = V D^2 V'
% % % % d <- sqrt(ret$values)
% % % % v <- ret$vectors
% % % % u <- X.std %*% v %*% diag(1/d)   # Why X V D^(-1)) = U?
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % \subsection{Cluster}
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{Clustering}\pause
% % % % \begin{lstlisting}
% % % % ### Clustering
% % % % set.seed(1234)                  # Set overall seed
% % % % X.kms <- kmeans(X.std, 3)       # K-means
% % % % X.kms
% % % % X.kms.cid <- X.kms$cluster      # Classification
% % % % 
% % % % library(EMCluster)              # Model-based clustering
% % % % X.mbc <- init.EM(X.std, 3)      # Initial by em-EM
% % % % X.mbc
% % % % X.mbc.cid <- X.mbc$class        # Classification
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{Cluster Validation}\pause
% % % % \begin{lstlisting}
% % % % ### Validation
% % % % X.kms.adjR <- RRand(X.cid, X.kms.cid)$adjRand       # Adjusted Rand index
% % % % X.mbc.adjR <- RRand(X.cid, X.mbc.cid)$adjRand
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{Cluster ID Variable}\pause
% % % % \begin{lstlisting}
% % % % ### Swap classification id
% % % % X.kms.cid[X.kms.cid == 2] <- 4
% % % % X.kms.cid[X.kms.cid == 3] <- 2
% % % % X.kms.cid[X.kms.cid == 4] <- 3
% % % % X.mbc.cid[X.mbc.cid == 2] <- 4
% % % % X.mbc.cid[X.mbc.cid == 3] <- 2
% % % % X.mbc.cid[X.mbc.cid == 4] <- 3
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % \subsection{Plot}
% % % % 
% % % % \begin{frame}[fragile]
% % % %   \begin{block}{Plot}\pause
% % % % \begin{lstlisting}
% % % % ### Display on first 2 components
% % % % pdf("serial_plot.pdf")
% % % % 
% % % % par(mfrow = c(2, 2))
% % % % plot(X.prj, col = X.cid + 1, pch = X.cid,
% % % %      main = "iris (true)", xlab = "PC1", ylab = "PC2")
% % % % plot(X.prj, col = X.kms.cid + 1, pch = X.kms.cid,
% % % %      main = paste("iris (k-Means)", sprintf("%.4f", X.kms.adjR)),
% % % %      xlab = "PC1", ylab = "PC2")
% % % % plot(X.prj, col = X.mbc.cid + 1, pch = X.mbc.cid,
% % % %      main = paste("iris (Model-based)", sprintf("%.4f", X.mbc.adjR)),
% % % %      xlab = "PC1", ylab = "PC2")
% % % % accuracy <- c(X.kms.adjR, X.mbc.adjR)
% % % % names(accuracy) <- c("k-Means", "Model-based")
% % % % barplot(accuracy, main = "Clustering Accuracy")
% % % % 
% % % % dev.off()
% % % % \end{lstlisting}
% % % % \end{block}
% % % % \end{frame}
% % % % 
% % % % 
% % % % \begin{frame}
% % % %   \begin{block}{Plot}\pause
% % % % \begin{center}
% % % %   \includegraphics[scale=.37]{other/serial_plot.pdf}
% % % % \end{center}
% % % % \end{block}
% % % % \end{frame}


\section[Iris]{In-Depth Example Examining the Iris Dataset with pbdR}

\hidenum
\begin{frame}[noframenumbering]
\frametitle{Contents}
 \tableofcontents[currentsection,hideothersubsections,sectionstyle=show/hide]
\end{frame}
\shownum

\subsection{Examining the Iris Dataset}

\begin{frame}[fragile]
  \begin{block}{The Iris Dataset}\pause
\begin{lstlisting}
rm(list = ls())                    # Clean environment

library(pbdDMAT, quiet = TRUE)     # Load library
init.grid()
if(comm.size() != 4)
  comm.stop("4 processors are required.")

### Load data
X <- as.matrix(iris[, -5])         # Dimension 150 by 4
X.cid <- as.numeric(iris[, 5])     # True id

### Convert to ddmatrix
X.dmat <- as.ddmatrix(X)
\end{lstlisting}
\end{block}
\end{frame}


\begin{frame}[fragile]
  \begin{block}{Standardizing}\pause
\begin{lstlisting}
### Standardized
X.std <- scale(X.dmat)
mu <- as.matrix(colMeans(X.std))
cov <- as.matrix(cov(X.std))
comm.print(mu)
comm.print(cov)
\end{lstlisting}
\end{block}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Projection Onto First 2 PC's}\pause
\begin{lstlisting}
### SVD
X.svd <- svd(X.std)

### Project on column space of singular vectors
A <- X.svd$u %*% diag(X.svd$d, type="ddmatrix")
B <- X.std %*% X.svd$v            # A ~ B
X.prj <- as.matrix(A[, 1:2])      # Only useful for plot
\end{lstlisting}
\end{block}
\end{frame}

\subsection{Cluster}

\begin{frame}[fragile]
  \begin{block}{Clustering}\pause
\begin{lstlisting}
### Clustering
library(pmclust, quiet = TRUE)
comm.set.seed(123, diff = TRUE)

X.dmat <- X.std
PARAM.org <- set.global.dmat(K = 3)      # Preset storage
.pmclustEnv$CONTROL$debug <- 0           # Disable debug messages
PARAM.org <- initial.center.dmat(PARAM.org)
PARAM.kms <- kmeans.step.dmat(PARAM.org) # K-means
X.kms.cid <- as.vector(.pmclustEnv$CLASS.dmat)
\end{lstlisting}
\end{block}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Cluster Validation}\pause
\begin{lstlisting}
### Validation
X.kms.adjR <- EMCluster::RRand(X.cid, X.kms.cid)$adjRand
comm.print(X.kms.adjR)
\end{lstlisting}
\end{block}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Cluster ID Variable}\pause
\begin{lstlisting}
### Swap classification id
tmp <- X.kms.cid
X.kms.cid[tmp == 1] <- 3
X.kms.cid[tmp == 2] <- 1
X.kms.cid[tmp == 3] <- 2
\end{lstlisting}
\end{block}
\end{frame}

\subsection{Plot}

\begin{frame}[fragile]
  \begin{block}{Plot}\pause
\begin{lstlisting}
### Display on first 2 components
if(comm.rank() == 0){
  pdf("dmat_plot.pdf")
  
  par(mfrow = c(2, 2))
  plot(X.prj, col = X.cid + 1, pch = X.cid,
       main = "iris (true)", xlab = "PC1", ylab = "PC2")
  plot(X.prj, col = X.kms.cid + 1, pch = X.kms.cid,
       main = paste("iris (kmeans)", sprintf("%.4f", X.kms.adjR)),
       xlab = "PC1", ylab = "PC2")
  
  dev.off()
}
\end{lstlisting}
\end{block}
\end{frame}


% \begin{frame}
%   \begin{block}{Plot}\pause
% \begin{center}
%   \includegraphics[scale=.37]{other/dmat_plot.pdf}\\
%  \vspace{-1cm}\url{http://www.nics.tennessee.edu/getting-an-allocation} 
% \end{center}
% \end{block}
% \end{frame}