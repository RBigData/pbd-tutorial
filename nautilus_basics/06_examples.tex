
\lsc{Examples}\label{egsec}
  \lsuc{A Monte Carlo Simulation}
You are probably familiar with the Monty Hall problem from the game show Let's Make a Deal.  If not, you might wish to read the \href{https://en.wikipedia.org/wiki/Monty_Hall_problem}{Wikipedia page} devopted to this problem.  A brief explanation is that the contestant is shown three doors to choose between.  Behind only one door is a prize.  The contestant chooses a door, and from the unchosen 2 doors, one is removed from play.  The contestant is then asked if he or she would like to switch from the initially chosen door to the only remaining door.  What is the probability of winning if the contestant switches?\\\\
%
We can easily simulate a play of this game with the R function \texttt{f()} defined as
\begin{lstlisting}[language=rr]
# Single game, assuming the player always switches
f <- function(.){
  prize.door <- sample(1:3, size=1)
  choice <- sample(1:3, size=1)

  if (choice==prize.door) return(0) else return(1) # Always switch
}
\end{lstlisting}

This is not necessarily the most efficient way to proceed.  Generally calling functions is costly, so it might make more sense to develop \texttt{f()} to take a ``number of runs'' argument, and this would probably improve the performance somewhat.  However, proceeding in our fashion is, for the sake of example, somewhat easier to follow in the various parallel implementations.

\subsubsection{Serial}
With the function \texttt{f} as above, it we can use \texttt{lapply()} to evaluate many runs
\begin{lstlisting}[language=rr]
n <- 1e7 # number of trials

system.time({
  mean(unlist(lapply(X=1:n, FUN=f)))
})
\end{lstlisting}
If this code is stored in the file serial.R, then you might submit it to Nautilus via the job file (remember to change ``your-account-number'' below to your actual account number.  Use the command \texttt{showusage}):
\begin{lstlisting}[language=sh]
#PBS -N Serial_sim_example
#PBS -S /bin/bash
#PBS -A your-account-number
#PBS -j oe
#PBS -l ncpus=8
#PBS -l walltime=1:00:00
#PBS -q analysis

module load r

R CMD BATCH serial.R
\end{lstlisting}%%%
Notice that we are asking for 8 cores, even though we are only going to use 1.  Remember that asking for 1 really takes 8 anyway.\\\\
%
Submitting this job results in the run time:
\begin{lstlisting}[language=rr]
   user  system elapsed 
187.275   0.220 187.516 
\end{lstlisting}


\subsubsection{Multicore}
With multicore, there is not much that we have to change over the serial implementation
\begin{lstlisting}[language=rr]
n <- 1e7 # number of trials
cores <- 10 # number of cores

library(multicore)

system.time({
  # mclapply() instead of lapply()
  mean(unlist(mclapply(X=1:n, FUN=f, mc.cores=cores)))
})
\end{lstlisting}

The \texttt{mclapply()} functions has the option \texttt{set.seed=} which defaults to \texttt{TRUE}.  This ensures that parallel processes have different seeds, which of course is very important for Monte Carlo simulation, since otherwise independence of the trials is violated.\\\\
%
If this code is stored in the file multicore.R, then you might submit it to Nautilus via the job file:

\begin{lstlisting}[language=sh]
#PBS -N Multicore_sim_example
#PBS -S /bin/bash
#PBS -A your-account-number
#PBS -j oe
#PBS -l ncpus=8
#PBS -l walltime=1:00:00
#PBS -q analysis

module load r
export TMPDIR=$HOME
export LC_ALL=C

cd $PBS_O_WORKDIR
R CMD BATCH multicore.R
\end{lstlisting}%%%
Submitting this job results in the run time:
\begin{lstlisting}[language=rr]
   user  system elapsed 
162.329   2.208  61.459 
\end{lstlisting}


\subsubsection{SNOW}
\begin{lstlisting}[language=rr]
n <- 1e7 # number of trials
cores <- 10 # number of cores

library(rlecuyer) # for parallel rng
library(snow)

system.time({
  # set up the workers
  cl <- makeCluster(cores, type="SOCK")
  
  # Pass objects to the workers
  clusterExport(cl, c("n", "cores", "f"))

  # parLapply() instead of lapply()
  mean(unlist(parLapply(cl=cl, x=1:n, fun=f)))
  stopCluster(cl)
})
\end{lstlisting}

If this code is stored in the file snow.R, then you might submit it to Nautilus via the job file:

\begin{lstlisting}[language=sh]
#PBS -N SNOW_sim_example
#PBS -S /bin/bash
#PBS -A your-account-number
#PBS -j oe
#PBS -l ncpus=8
#PBS -l walltime=1:00:00
#PBS -q analysis

module load r

R CMD BATCH snow.R
\end{lstlisting}%%%
Submitting this job results in the run time:
\begin{lstlisting}[language=rr]
   user  system elapsed 
 86.069   2.720 124.031 
\end{lstlisting}


\subsubsection{Rmpi}
Generally speaking, Rmpi is a bit trickier.  MPI is very powerful, and with that power comes a slightly more complicated API than with those above.  Since Nautilus is a shared memory machine, there is no real advantage to using Rmpi over Multicore; generally you should expect the runtimes to roughly be the same.  However, if you are on a distributed memory cluster, then there is only so much you can do with Multicore.  \\\\
%
Multicore operates on one node, with as many cores used within that node as possible/requested.  Nautilus is basically one big node, so Multicore can utilize all of its cores.  On a distributed memory cluster, this is not so, and the number of cores that can be utilized by Multicore will be significantly lower than can be utilized by Rmpi, and whence the potential speedup gained by Multicore on such systems pales in comparison for very big jobs.\\\\
%
Here there is a very important difference over Multicore and SNOW.  We \emph{must} make explicit steps to ensure that the random number generation operates appropriately on the workers.  Here, we do so with the \href{http://cran.r-project.org/web/packages/rlecuyer/index.html}{rlecuyer} package for R.  This can also be done with the \href{http://cran.r-project.org/web/packages/rsprng/index.html}{rsprng} package.\\\\
%
Here for consistency with the previous examples, we will use \texttt{mpi.parLapply()}, though arguably \texttt{mpi.parSim()} is more appropriate.  \\\\
%
See the \href{http://cran.r-project.org/web/packages/Rmpi/Rmpi.pdf}{rmpi documentation} for more details about the Rmpi API.
\begin{lstlisting}[language=rr]
n <- 1e7 # number of trials

library(rlecuyer) # for parallel rng
library(Rmpi)

system.time({
  mpi.spawn.Rslaves(needlog = FALSE)

  # set up parallel rng on the slaves
  mpi.setup.rngstream() 

  # mpi.parLapply() instead of lapply()
  mean(unlist(vec <- mpi.parLapply(x=1:n, fun=f)))
})

mpi.close.Rslaves(dellog = FALSE)
mpi.exit()
\end{lstlisting}

If this code is stored in the file rmpi.R, then you might submit it to Nautilus via the job file:

\begin{lstlisting}[language=sh]
#PBS -N Rmpi_sim_example
#PBS -S /bin/bash
#PBS -A your-account-number
#PBS -j oe
#PBS -l ncpus=8
#PBS -l walltime=1:00:00
#PBS -q analysis

module load r
module swap mpt mpt/2.04
export LC_ALL=C
export TMPDIR=$PBS_O_WORKDIR

cd $PBS_O_WORKDIR
mpirun -np 8 Rscript rmpi.R
\end{lstlisting}%%%
Submitting this job results in the run time:
\begin{lstlisting}[language=rr]
   user  system elapsed 
 99.370   1.088 100.581 
\end{lstlisting}


\lsuc{Linear Model Selection}
For the remainder, example job scripts will be suppressed, since they are effectively the same as those found in the examples above.\\\\
%
In this example, we will randomly generate a random normal response variable $y$, 10 random normal predictor variables $x$ and evaluate all possible $2^{10} -1 = 1023$ models which contain at least one predictor variable and choose a best model by the \href{https://en.wikipedia.org/wiki/Bayesian_information_criterion}{Bayesian Information Criterion}.\\\\
%
First we need to generate the data.  Since this is not the focus of this demonstration, we will do it once, independent of the parallel implementation.  
\begin{lstlisting}[language=rr]
n <- 1e7 # number of rows to generate

# The data
nvars <- 10
x <- matrix(rnorm(n*nvars), ncol=nvars)
y <- rnorm(n)

write.csv(data.frame(x, y), "simdata.csv")
\end{lstlisting}
A quick word of warning, it is possible that some of the models will have infinite likelihood, and no extra precaution is taken in the code to follow to prevent such an occurrence.  If you are getting strange errors, try generating a new dataset.  \\\\
%
Once this dataset has been generated, we can use the same simulated data each time in our testing of various parallel implementations.

\subsubsection{Serial}
Here, we will just have a single \texttt{for} loop that will run through the models one at a time.  This is not necessarily efficient, even ignoring running things in parallel, but this is the simplest way one might prototype a solution to this problem.  \\\\
%
For each model to be evaluated, the model is fit and its BIC score is calculated.  A comparison is made to that BIC score and the yet lowest observed BIC, and if the model BIC is lower than the previous best BIC, then we make that model the new best.

\begin{lstlisting}[language=rr]
# Read in the data
df <- read.csv("simdata.csv")
x <- as.matrix(df[1:10])
y <- as.matrix(df[11])

# Generate the list of models to evaluate
col.opt <- lapply(X=1:ncol(x), FUN=function(.) 0:1)
models.list <- expand.grid(col.opt)
models.list <- models.list[-1, ] # prune first row

# Fit the models
system.time({
  best <- Inf
  for (i in 1:nrow(models.list)){
    subst <- which(models.list[i, ] == 1)
    test <- BIC(lm(y~x[, subst]))
    if (test < best) {
      best <- test
      best.subst <- subst
    }
  }
})

# Print the output
cat(sprintf("The optimal model is that with predictors:  %s\n", paste(paste("x", best.subst, sep=""), collapse=", ")))
cat(sprintf("With BIC:  %f\n", best))
\end{lstlisting}


\subsubsection{Multicore}\label{mcmodelsel}
Here a slight change in philosophy is required.  Instead of fitting one model at a time, we fit models independently in parallel on different cores, and each time a model is evaluated, we store in a list which model we were looking at and its corresponding BIC score.  Then after we have all of the BIC scores calculated and corresponding model information, we look through the list of all BIC scores and choose the smallest such.  The model corresponding to this BIC score is then determined from the stored subset information, and is declared to be the best model.
\begin{lstlisting}[language=rr]
# Number of cores to use
cores <- 8

# Read in the data
df <- read.csv("simdata.csv")
x <- as.matrix(df[1:10])
y <- as.matrix(df[11])

# Generate the list of models to evaluate
col.opt <- lapply(X=1:ncol(x), FUN=function(.) 0:1)
models.list <- expand.grid(col.opt)
models.list <- models.list[-1, ] # prune first row


library(multicore)

f <- function(i){
  subst <- which(models.list[i, ] == 1)
  bic <- BIC(lm(y~x[, subst]))
  return(list(bic=bic, subst=subst))
}

# Fit all models, find the best among them later
system.time({
  models <- mclapply(X=1:nrow(models.list), FUN=f)
  bics <- sapply(models, "[[", 1)

  best <- min(bics)
  best.subst <-  which(models.list[which(bics==best), ] == 1)
})

# Printing output
cat(sprintf("The optimal model is that with predictors:  %s\n", paste(paste("x", best.subst, sep=""), collapse=", ")))
cat(sprintf("With BIC:  %f\n", best))
\end{lstlisting}


\subsubsection{SNOW}
Here we use the same philosophy in the Multicore solution from \ref{mcmodelsel}, with only slight modifications for use with SNOW.
\begin{lstlisting}[language=rr]
# Number of cores to use
cores <- 8

# Read in the data
df <- read.csv("simdata.csv")
x <- as.matrix(df[1:10])
y <- as.matrix(df[11])

# Generate the list of models to evaluate
col.opt <- lapply(X=1:ncol(x), FUN=function(.) 0:1)
models.list <- expand.grid(col.opt)
models.list <- models.list[-1, ] # prune first row


library(snow)

f <- function(i){
  subst <- which(models.list[i, ] == 1)
  bic <- BIC(lm(y~x[, subst]))
  return(list(bic=bic, subst=subst))
}

# Fit all models, find the best among them later
system.time({
  # Create cluster
  cl <- makeCluster(cores, type="SOCK")

  # Pass objects to the workers
  clusterExport(cl, c("cores", "x", "y", "f", "models.list"))  
  
  models <- parLapply(cl=cl, x=1:nrow(models.list), fun=f)
  bics <- sapply(models, "[[", 1)

  best <- min(bics)
  best.subst <-  which(models.list[which(bics==best), ] == 1)

  stopCluster(cl)
})

# Printing output
cat(sprintf("The optimal model is that with predictors:  %s\n", paste(paste("x", best.subst, sep=""), collapse=", ")))
cat(sprintf("With BIC:  %f\n", best))
\end{lstlisting}

\subsubsection{Rmpi}
Using Rmpi here feels very much like using SNOW.
\begin{lstlisting}[language=rr]
# Number of cores to use
cores <- 8

# Read in the data
df <- read.csv("simdata.csv")
x <- as.matrix(df[1:10])
y <- as.matrix(df[11])

# Generate the list of models to evaluate
col.opt <- lapply(X=1:ncol(x), FUN=function(.) 0:1)
models.list <- expand.grid(col.opt)
models.list <- models.list[-1, ] # prune first row


library(Rmpi)

f <- function(i){
  subst <- which(models.list[i, ] == 1)
  bic <- BIC(lm(y~x[, subst]))
  return(list(bic=bic, subst=subst))
}

# Fit all models, find the best among them later
system.time({
  mpi.spawn.Rslaves(needlog=FALSE)

  # Pass objects to the workers
  mpi.bcast.Robj2slave(x)
  mpi.bcast.Robj2slave(y)
  mpi.bcast.Robj2slave(f)

  susbests <- mpi.parLapply(X=1:nrow(models.list), FUN=function(i) which(models.list[i, ] == 1))
  mpi.bcast.Robj2slave(subsets)
  
  models <- mpi.parLapply(x=subsets, fun=f)
  bics <- sapply(models, "[[", 1)
  
  best <- min(bics)
  best.subset <- which(models.list[which(bics==best), ] == 1)
})

mpi.close.Rslaves(dellog=FALSE)
mpi.exit()

# Printing output
cat(sprintf("The optimal model is that with predictors:  %s\n", paste(paste("x", best.subst, sep=""), collapse=", ")))
cat(sprintf("With BIC:  %f\n", best))
\end{lstlisting}

\subsubsection{foreach}
Finally, we do the same with foreach.
\begin{lstlisting}[language=rr]
# Number of cores to use
cores <- 8

# Read in the data
df <- read.csv("simdata.csv")
x <- as.matrix(df[1:10])
y <- as.matrix(df[11])

# Generate the list of models to evaluate
col.opt <- lapply(X=1:ncol(x), FUN=function(.) 0:1)
models.list <- expand.grid(col.opt)
models.list <- models.list[-1, ] # prune first row


library(foreach)
library(multicore)
library(doMC)

registerDoMC(cores=cores)

# Fit all models, find the best among them later
system.time({
  models <- foreach (i=1:nrow(models.list)) %dopar% {
    subst <- which(models.list[i, ] == 1)
    test <- BIC(lm(y~x[, subst]))

    list(test, subst)
  }

  bics <- sapply(models, "[[", 1)
  best <- min(bics)
  best.subst <-  which(models.list[which(bics==best), ] == 1)
})

# Printing output
cat(sprintf("The optimal model is that with predictors:  %s\n", paste(paste("x", best.subst, sep=""), collapse=", ")))
cat(sprintf("With BIC:  %f\n", best))
\end{lstlisting}
